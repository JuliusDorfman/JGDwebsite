---
title: "Humans on the Support Team in 2026: Something to Solve For?"
description: "When the customer has access to a tool that knows the product better than you do..."
date: "2026-02-25"
tags: ["saas", "support", "customer-support", "ai", "ai-in-support", "technical-support", "support-engineer"]
---
<div className="blog-pull-quote">

<span className="blog-lead-big neon-red">> Why are things changing so dang much?</span>
</div> 

The <span className="support-team">Support Team</span>'s duties are reactive to the needs of the user. Those needs shift on a daily, weekly, and as we're now experiencing, generational basis. In the mid '90s <span className="neon-white">Microsoft</span>'s user base exploded by the millions. That's a lot of human bandwidth dedicated to closing the "Where is my 'ANY' key?" tickets. How do you solve for an inundated <span className="support-team">Support Team</span>? <span className="neon-white">Customer self-enablement</span>. Microsoft began publishing FAQs for customers to help themselves. This, now industry standard, shifted the <span className="support-team">Support Team</span>'s responsibilities from <span className="blog-dim">answer every user question</span> to <span className="neon-white">answer every question users can't answer themselves</span>. Sound familiar? <span className="neon-cyan">AI is doing it again.</span>

The difference is that, according to Gartner, by 2029 <span className="blog-dim">(an extremely conservative estimate IMO)</span>, [agentic AI will resolve <span className="neon-cyan underline">80%</span> of incoming customer queries](https://www.gartner.com/en/newsroom/press-releases/2025-03-05-gartner-predicts-agentic-ai-will-autonomously-resolve-80-percent-of-common-customer-service-issues-without-human-intervention-by-20290) without requiring any human bandwidth at all.

So if your product's AI assistant handles a majority of tickets now...

<div className="blog-pull-quote">

<span className="neon-red">> What's left for the humans?</span>

</div>

The embedded AI assistant in your SaaS product is servicing a new generation of technically-inclined users who instinctively self-troubleshoot. Ergo, nobody is reaching out for a <span className="blog-dim">post-sale product walkthrough</span>, <span className="blog-dim">UI navigation issue</span>, or <span className="blog-dim">"how do I..."</span>. Touch and go interactions are extinct. Yes, your ticket queue has not only gotten shorter, but the 
<span className="neon-white">substance is more demanding, the resolutions are more complex, and your touches per ticket are more numerous</span>.

So that brings us to... 

<div className="blog-pull-quote">

<span className="blog-lead-big neon-red">> Why We Still Need People In Support</span>

</div> 

<span className="blog-section-label" style={{color: '#ff4141'}}>Pillar one</span>

<h2 className="neon-cyan">Perceived Accountability</h2>

When an AI assistant tells your dissatisfied client, <span className="blog-dim">"We understand how important this is to you"</span> ... who is "We"? Is it the company dev who plugged in your API Key authorizing the $0.00015â€“$0.0003 charge per 1,000 tokens outputting a "We Care" pattern-matched statement? It certainly isn't the AI Assistant. It takes a Being capable of the <span className="neon-cyan">Conscious Human Experience</span> to take accountability.
We haven't yet been able to simulate the conscious human experience and so, neither can we simulate accountability. In 2024, Canadian courts held [Air Canada liable](https://www.americanbar.org/groups/business_law/resources/business-law-today/2024-february/bc-tribunal-confirms-companies-remain-liable-information-provided-ai-chatbot/) after its AI chatbot promised to honor a non-existent refund policy. Legislatively, <span className="neon-white">it appears AI accountability is following the same logic as animal ownership</span>. The difference is that problematic pets can be dealt with in a way meaningful to the <span className="neon-cyan">Conscious Human Experience</span> that satisfies the wronged party, and, ostensibly, demands accountability from the owner. In other words, while both are seperate but associated entities, a pet is an accountability-extension while an AI Assistant is merely an accountability-proxy. The subtext here is that you cannot hold an AI Assistant personally accountable in any substantive way to a dissatisfied customer.

On an organizational level, a failure of duties needs to be attributed to someone in a meaningful way that ensures better future outcomes. On a customer relationship level, the customer needs to be able to <span className="neon-purple">feel</span> that there will be meaningful consequences to a failure in duties. AI Assistants, incapable of simulating the <span className="neon-cyan">Conscious Human Experience</span>, rob this attribution of accountability on every level. 

<div className="blog-neon-rule" />

<span className="blog-section-label" style={{color: '#ff4141'}}>Pillar two</span>

<h2 className="neon-cyan">Throughput vs Situational Awareness</h2>

Your AI Assistant can process more tickets than a team of 1,000 Human Support Agents. It can also organize them by priority and urgency. It can also roadmap and triage these issues for the appropriate teams and even write documentation along the way. 

<div><span className="neon-red">But...</span></div>

<div><span className="blog-lead-small neon-cyan">Support is still, and will always be about, Customer Service.</span></div>
<br />

I'll leave it up to you to think about all the different ways you've had food delivered to your table.

Your AI Agent hasn't been to your most recent weekly stand-up. It also doesn't know which Product Engineer is the backup SME on the new feature that just soft-launched to a handful of your Enterprise SLA clients comprising 80% of your MRR, or what tone is appropriate in a new communication with the customer's developer in charge of product integration before a critical release.

There's a difference between achieving <span className="neon-cyan">a satisfying experience by smoothing the interstitial frictions of collaboration</span>... VS... <span className="blog-dim">appropriate individuals have been alerted -> tasks complete -> initiating next unavoidable collaboration event.</span> 

Though... in another universe...
<span className="neon-red">Initiating: NPS SCORE MAXIMIZATION PROTOCOL</span>

<br />

<span className="blog-callout"> [What is an NPS Score?](https://www.qualtrics.com/articles/customer-experience/net-promoter-score/) </span>

<div className="blog-neon-rule" />

<span className="blog-section-label" style={{color: '#ff4141'}}>Pillar three</span>

<h2 className="neon-cyan">Human Growth and Want</h2>

A human <span className="support-team">Support agent</span> is a collector of <span className="neon-cyan">peripheral data</span>. Remember those junior developer jobs that have ostensibly disappeared? Well, those humans are on your <span className="support-team">Support Team</span> now (always have been). They're <span className="neon-cyan">trend noticers</span> and <span className="neon-cyan">roadmap projectors</span>; these are your next Product Engineers and Product Managers whose context windows don't truncate and whose sessions have no token limit.

The <span className="neon-cyan">context</span> that doesn't explicitly pass through a matrix of keywords and patterns is the context that may not be optimal for ticket resolution, but it is the kind that leads to <span className="neon-cyan">innovation</span>. An AI Agent will never have experienced the <span className="neon-purple">want</span> of needing a solution and then experiencing the friction in achieving that solution. No friction -> no <span className="neon-purple">want</span> -> no innovation.

<div className="blog-callout">

Consider: no AI would have suggested replacing the <span className="neon-white">"Save" button</span> with incremental autosave and a change history tab; now a commonly adopted industry standard across giants and startups like <span className="blog-dim">Microsoft 365, Google Workspace, and Builder.io</span>. In fact, it may not be optimal for everyone. I've received a few tickets asking, "where did my save button go". Until the AI can juggle philosophies like utilitarianism and deontology and then apply that lens to a save button while taking into account what your best friend thinks, innovation is for the guy or gal who spent a year on the <span className="support-team">Support Team</span>.

</div>

<div className="blog-neon-rule" />

<span className="blog-section-label" style={{color: '#e8e8e8'}}>So what now?</span>

<h2 className="neon-cyan">The Bar Isn't Lower, It's Different</h2>


The AI Assistant didn't replace your <span className="support-team">Support Team</span>. It freed up your team's <span className="neon-purple">bandwidth</span>.

<span className="neon-red">So what's left?</span> 
<span className="neon-cyan">Empathy</span>, <span className="neon-cyan">relationships</span>, and <span className="neon-purple">want</span>. These are the non-simulateable, and non-optimizable, and non-automatable aspects of the <span className="neon-cyan">Conscious Human Experience</span> that make humans capable of holding the <span className="neon-cyan">accountability</span> that builds mutual trust between your company and your customers. <span className="neon-red">And Raise those NPS Scores.&#128578;</span>



<div className="blog-neon-rule" />

<div className="blog-pull-quote">

AI is a tool for optimizing ticket resolution. The humans on the <span className="support-team">Support Team</span> now have a new and powerful tool to optimize for the best possible <span className="neon-cyan">Conscious Human Experience</span> of your customers.

</div>

<div className="blog-neon-rule" />
